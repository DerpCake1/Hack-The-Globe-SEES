{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104499,"databundleVersionId":12821543,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12346817,"sourceType":"datasetVersion","datasetId":7783605}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Hack The Globe Notebook: Jordan Tran\n\nFor the past 2 weeks, using a sample of GLOBE's dataset, I explored ways to improve the quality of the dataset through an interpretable flagging system and generating metadata.\n\n\n#### Exploration:\nIn order to improve the surface temperature dataset and make data more avaliable for future researchers, I decided to explore metadata augmentation of the dataset, which introduce new pieces of data that could be used for models or to identify trends not previously obvious with the original set of data.\n\nCountry/Continent/Biome data was to enrich the dataset with new information based off the coordinates recieved.\n\nYear/Month/Country Code was generated in order to make future data projects easier with the dataset.\n\n#### Takeaways:\n\nThrough this project I learned more about how to use dataframes to generate new data that wasn't explicitly given, the applications for what this new data could be used for, as well as the science behind surface temperature and strategies to classify outliers in our specific dataset.\n","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries\n\n**Pandas** is used to store the parquet into a dataframe which allows vectorization and manipulating the data through entire columns\n\n\n**pycountry_convert, reverse_geocode, and folium** are all libraries not installed into the kaggle environment and must be *pip installed*","metadata":{}},{"cell_type":"code","source":"!pip install pycountry_convert\n!pip install reverse_geocode\n!pip install folium\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# libraries for metadata augmentation\nimport reverse_geocode\nimport pycountry_convert as pc\nimport geopandas as gpd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Initialize Data\n\nPandas will convert the original surface temperature parquet into a dataframe that can be used to generate new columns to improve the data.\n\nIn order to generate **Biome** data, an external shape file (.shp) along with its helper files must be downloaded. Complete the following steps to generate the biome column.\n\n1. Download, and unpack the zip file onto your local device. (https://files.worldwildlife.org/wwfcmsprod/files/Publication/file/6kcchn7e3u_official_teow.zip)\n2. Move ONLY **.dbf, .prj, .shp, .shx** to the current directory.\n3. When accessing the shape file (see in **biome**), ensure that the file path is where the file is located on your LOCAL device.\n```\nglobal_biomes = gpd.read_file(\"INSERT PATH HERE/wwf_terr_ecos.shp\")\n```","metadata":{}},{"cell_type":"code","source":"# Modifies Pandas settings to view only a set amount of rows and columns; used to display only a small subset of values while viewing all columns\npd.options.display.max_columns = 70\npd.options.display.max_rows = 20\n\n# Initializes the dataframe, provides the data types of all columns, and displays the dataset in a table\n# IF DOWNLOADED ON LOCAL DEVICE, PLEASE CHANGE THE FILE PATH TO WHERE THE PARQUET IS STORED\ndf = pd.read_parquet('/kaggle/input/hack-the-globe/mv_surface_temperatures_wide.parquet')\ndisplay(df.info())\ndisplay(df)\n\n# Percent of missing values per column (WRITTEN BY MARLIN WONG)\npd.options.display.max_rows = 100\nmissing = df.isnull().mean().sort_values(ascending=False) * 100\nprint(missing[missing > 0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Metadata Augmentation\n\nMetadata augmentation uses the provided data and generates new data that can be used to improve future models and provide more information about a given datapoint.\n\nColumns were added for the purposes of providing information that wasn't previously given in dataset, as well as making avaliable information easier to access for future data projects.\n\nMetadata added:\n- Countries\n- Country Code\n- Continent\n- Year\n- Month\n- Biome","metadata":{}},{"cell_type":"markdown","source":"### Country / Country Code / Continent\n\nUseful to compare surface temperature for country, i.e (avg surface temp of 1 country vs. another)","metadata":{}},{"cell_type":"code","source":"# uses an offline library to reverse geocode the country that data was taken in through its site latitude and longitude.\n# MISSING DATA RETURNS \"\" FOR BOTH COUNTRY AND COUNTRY CODE\ndef reverse_geo(lat, lon):\n    if pd.isna(lat) or pd.isna(lon):\n        return None, None\n\n    coords = [(lat, lon)]\n    # Perform reverse geocoding\n    location = reverse_geocode.search(coords)\n    \n    # Extract country information\n    if location:\n        return location[0].get(\"country\"), location[0].get(\"country_code\")\n    else:\n        return \"\", \"\"\n\n# function that takes a given row's latitude and longitude in order to use .apply and make a new column with countries\ndef get_country_from_row(row):\n    lat = row['site_latitude']\n    lon = row['site_longitude']\n    return reverse_geo(lat, lon)\n\n\nreverse_geo(37.698551,-122.073959) # test case\ndf[[\"country\", 'country_code']] = df.apply(get_country_from_row, axis=1, result_type='expand')\ndisplay(df[\"country_code\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# uses pycountry_convert to turn a country name into its respective continent\n# MISSING DATA RETURNS \"\" FOR CONTINENT\ndef country_to_continent(country):\n    try:\n        country_alpha2 = pc.country_name_to_country_alpha2(country)\n        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n        return country_continent_name\n    except:\n        return \"\"\n\ndef get_cont_from_row(row):\n    return country_to_continent(row[\"country\"])\n\nprint(country_to_continent(\"Poland\")) # test case\ndf[\"continent\"] = df.apply(get_cont_from_row, axis=1)\ndisplay(df[\"continent\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Year / Month","metadata":{}},{"cell_type":"code","source":"# \"Measured_at\" is in datetime64[ns], which year and month can be extracted from through pandas\ndf['year'] = df['measured_at'].dt.year\ndf['month'] = df['measured_at'].dt.month\ndisplay(df['month'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Biomes\n\nThe global biome data is sourced from World Wildlife Fund's (WWF) Terrestrial Ecoregions of the World. \n\nDOI: https://doi.org/10.1641/0006-3568(2001)051[0933:TEOTWA]2.0.CO;2\n\nWWF's Publication: https://www.worldwildlife.org/publications/terrestrial-ecoregions-of-the-world\n\nDownload URL: https://files.worldwildlife.org/wwfcmsprod/files/Publication/file/6kcchn7e3u_official_teow.zip","metadata":{}},{"cell_type":"code","source":"# Creates polygons out of WWF's .shp file, and overlays site coordinates over it to determine each point's biome\n# IF RUNNING ON LOCAL DEVICE\nglobal_biomes = gpd.read_file(\"/kaggle/input/global-biome-dataset/wwf_terr_ecos.shp\")\n\n# turns site coordinates into 'Point' datatypes for geopanadas\npoints = gpd.points_from_xy(df['site_longitude'],df[\"site_latitude\"])\n\ngdf = gpd.GeoDataFrame(df, geometry=points, crs=\"EPSG:4326\")\n\nbiomes = global_biomes.to_crs(\"EPSG:4326\")\n\n# creates a new dataframe which intersects the original dataframe with the geopandas one\nresult = gpd.sjoin(gdf, biomes, how=\"left\", predicate='intersects')\ndf['biome'] = result[\"ECO_NAME\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Return the dataframe back to a parquet that is exported to the current directory for future use\ndf.to_parquet(\"updated_meta_HTG_data.parquet\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}